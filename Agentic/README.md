This section is solely based on Agentic AI practices, methods, scenarios and implementations.

List of Implemented Agents
 1. Simple Reflex Agent: Moves randomly across the grid.
 2. Model-Based Reflex Agent: Moves randomly but remembers past visits.
 3. Goal-Based Agent: Uses BFS to find the shortest path to the nearest treasure.
 4. Utility-Based Agent: Uses A* algorithm to find the optimal path to the nearest treasure.
 5. Learning Agent: Learns from the environment and improves its performance over time.
 6. Hybrid Agent: Combines the features of the above agents to make decisions.
 7. Greedy Agent: Uses a heuristic to find the shortest path to the nearest treasure.
 8. A* Agent: Uses A* algorithm to find the optimal path to the nearest treasure.
 9. Q-Learning Agent: Uses Q-learning to learn the optimal policy for the grid world.
 10. SARSA Agent: Uses SARSA to learn the optimal policy for the grid world.

Scenarios:
1. The PuzzleWithEnemies represents a simple 2D grid-based environment where an agent can move around, collect treasures, and interact with a switch and a door.
2. The TresureHunting represents a simple 2D grid-based and randomly generated environment where an agent can move around, collect treasures, and avoid obstacles.
